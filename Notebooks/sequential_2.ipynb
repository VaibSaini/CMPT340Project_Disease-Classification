{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sequential-2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NaTvejVH9um9"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RRv0Mlw95E5"
      },
      "source": [
        "#seq model 2\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFl3QwOl93To",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acefe6c0-7a5d-4c90-bd95-a37f172dc851"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling2D, MaxPooling1D, Dense, Flatten, Dropout, SeparableConv1D\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.model_selection import train_test_split\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from tensorflow.keras.utils import plot_model,to_categorical\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "%cd gdrive/MyDrive/'CMPT 340 Project'/audio_and_txt_files"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/.shortcut-targets-by-id/1e1OTACsf9h9Mi5uoqIsDyb3h904F6VDk/CMPT 340 Project/audio_and_txt_files\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-DdaG7193WB"
      },
      "source": [
        "diagnosis_df = pd.read_csv('/content/gdrive/MyDrive/CMPT 340 Project/patient_diagnosis.csv', names=['Patient number', 'Diagnosis'])\n",
        "df_no_diagnosis = pd.read_csv('/content/gdrive/MyDrive/CMPT 340 Project/demographic_info.txt', names = ['Patient number', 'Age', 'Sex' , 'Adult BMI (kg/m2)', 'Child Weight (kg)' , 'Child Height (cm)'], delimiter = ' ')\n",
        "df =  df_no_diagnosis.join(diagnosis_df.set_index('Patient number'), on = 'Patient number', how = 'left')\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29FjFmK4-yDJ"
      },
      "source": [
        "root = '/content/gdrive/MyDrive/CMPT 340 Project/audio_and_txt_files'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSAyOsDv-9lb"
      },
      "source": [
        "filenames = [s.split('.')[0] for s in os.listdir(path = root) if '.txt' in s] "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2p_F4fAc_D3J"
      },
      "source": [
        "def Extract_Annotation_Data(file_name, root):\n",
        "    tokens = file_name.split('_')\n",
        "    recording_info = pd.DataFrame(data = [tokens], columns = ['Patient number', 'Recording index', 'Chest location','Acquisition mode','Recording equipment'])\n",
        "    recording_annotations = pd.read_csv(os.path.join(root, file_name + '.txt'), names = ['Start', 'End', 'Crackles', 'Wheezes'], delimiter= '\\t')\n",
        "    return (recording_info, recording_annotations)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWUXgbVWAVRF"
      },
      "source": [
        "i_list = []\n",
        "rec_annotations = []\n",
        "rec_annotations_dict = {}\n",
        "for s in filenames:\n",
        "    (i,a) = Extract_Annotation_Data(s, root)\n",
        "    i_list.append(i)\n",
        "    rec_annotations.append(a)\n",
        "    rec_annotations_dict[s] = a\n",
        "recording_info = pd.concat(i_list, axis = 0)\n",
        "recording_info.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nkGV6S7AiZ6"
      },
      "source": [
        "class Diagnosis():\n",
        "    def __init__ (self, id, diagnosis, image_path):\n",
        "        self.id = id\n",
        "        self.diagnosis = diagnosis \n",
        "        self.image_path = image_path"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmgFOizRCnGM"
      },
      "source": [
        "def get_wav_files():\n",
        "    audio_path = '/content/gdrive/MyDrive/CMPT 340 Project/audio_and_txt_files/'\n",
        "    files = [f for f in listdir(audio_path) if isfile(join(audio_path, f))]  #Gets all files in dir\n",
        "    wav_files = [f for f in files if f.endswith('.wav')]  # Gets wav files \n",
        "    wav_files = sorted(wav_files)\n",
        "    return wav_files, audio_path\n",
        "\n",
        "# could be our implementation"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAwpJOCVC7rP"
      },
      "source": [
        "def diagnosis_data():\n",
        "    diagnosis = pd.read_csv('/content/gdrive/MyDrive/CMPT 340 Project/patient_diagnosis.csv')\n",
        "  \n",
        "    wav_files, audio_path = get_wav_files()\n",
        "    diag_dict = { 101 : \"URTI\"}  \n",
        "    diagnosis_list = []\n",
        "  \n",
        "    for index , row in diagnosis.iterrows():\n",
        "        diag_dict[row[0]] = row[1]     \n",
        "\n",
        "    c = 0\n",
        "    for f in wav_files:\n",
        "        print(f)\n",
        "        print(f[:3])\n",
        "        diagnosis_list.append(Diagnosis(c, diag_dict[float(f[:3])], audio_path+f))  \n",
        "        c+=1  \n",
        "\n",
        "    return diagnosis_list"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0kpn9X7Daf4"
      },
      "source": [
        "def audio_features(filename): \n",
        "    sound, sample_rate = librosa.load(filename)\n",
        "    stft = np.abs(librosa.stft(sound))  \n",
        " \n",
        "    mfccs = np.mean(librosa.feature.mfcc(y=sound, sr=sample_rate, n_mfcc=40),axis=1)\n",
        "    chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate),axis=1)\n",
        "    mel = np.mean(librosa.feature.melspectrogram(sound, sr=sample_rate),axis=1)\n",
        "    contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate),axis=1)\n",
        "    tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(sound), sr=sample_rate),axis=1)\n",
        "    \n",
        "    concat = np.concatenate((mfccs,chroma,mel,contrast,tonnetz))\n",
        "    return concat"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2zfbwyHDpn3"
      },
      "source": [
        "def data_points():\n",
        "    labels = []\n",
        "    images = []\n",
        "\n",
        "    to_hot_one = {\"COPD\":0, \"Healthy\":1, \"URTI\":2, \"Bronchiectasis\":3, \"Pneumonia\":4, \"Bronchiolitis\":5, \"Asthma\":6, \"LRTI\":7}\n",
        "\n",
        "    #count = 0\n",
        "    for f in diagnosis_data():\n",
        "        #print(count)\n",
        "        labels.append(to_hot_one[f.diagnosis]) \n",
        "        images.append(audio_features(f.image_path))\n",
        "        #count+=1\n",
        "\n",
        "    return np.array(labels), np.array(images)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PG68ykIEClP"
      },
      "source": [
        "path = '/content/gdrive/MyDrive/CMPT 340 Project/filename_differences.txt'\n",
        "\n",
        "diff = pd.read_csv(path, sep=\" \", header=None, names=['file_names'])\n",
        "diff.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vzp0yUxcEKuk"
      },
      "source": [
        "df =  diff.join(diagnosis_df,how = 'left')\n",
        "df.head(15)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLNZ_LcdE9D3"
      },
      "source": [
        "x1 = audio_features('/content/gdrive/MyDrive/CMPT 340 Project/audio_and_txt_files/106_2b1_Pl_mc_LittC2SE.wav')\n",
        "S1 = librosa.feature.melspectrogram(x1)\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.subplot(2,2,1)\n",
        "librosa.display.specshow(librosa.power_to_db(S1, ref=np.max))\n",
        "plt.title('COPD Mel spectrogram')\n",
        "plt.tight_layout()\n",
        "\n",
        "T1 = librosa.feature.mfcc(x1)\n",
        "plt.subplot(2,2,2)\n",
        "librosa.display.specshow(librosa.power_to_db(T1, ref=np.max))\n",
        "plt.title('COPD MFCC')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_IZ_EP1FI9m"
      },
      "source": [
        "def preprocessing(labels, images):    \n",
        "\n",
        "  # Remove Asthma and LRTI\n",
        "    # images = np.delete(images, np.where((labels == 7) | (labels == 6))[0], axis=0) \n",
        "    # labels = np.delete(labels, np.where((labels == 7) | (labels == 6))[0], axis=0)      \n",
        "    \n",
        "  # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=10)\n",
        "\n",
        "  # Hot one encode the labels\n",
        "    y_train = to_categorical(y_train)\n",
        "    y_test = to_categorical(y_test)  \n",
        "\n",
        "  # Format new data\n",
        "    y_train = np.reshape(y_train, (y_train.shape[0], 6))\n",
        "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
        "    y_test = np.reshape(y_test, (y_test.shape[0], 6))\n",
        "    X_test = np.reshape(X_test, (X_test.shape[0], X_train.shape[1],  1))\n",
        "\n",
        "    return X_train, X_test, y_train, y_test"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPFmTf3hF7vT"
      },
      "source": [
        "labels, images = data_points()\n",
        "X_train, X_test, y_train, y_test = preprocessing(labels, images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAraHDcgHIDO"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(64, kernel_size=5, activation='relu', input_shape=(193, 1)))\n",
        "\n",
        "model.add(Conv1D(128, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(2)) \n",
        "\n",
        "model.add(SeparableConv1D(256, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(2)) \n",
        "\n",
        "model.add(SeparableConv1D(256, kernel_size=5, activation='relu'))\n",
        "model.add(MaxPooling1D(2)) \n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(512, activation='relu'))   \n",
        "model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=70, batch_size=200, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imfN4a26HIGG"
      },
      "source": [
        "def visualize_training(history, lw = 3):\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n",
        "    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n",
        "    plt.title('Training Accuracy vs Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend(fontsize = 'x-large')\n",
        "    plt.show()\n",
        "\n",
        "    plt.figure(figsize=(10,6))\n",
        "    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n",
        "    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n",
        "    plt.title('Training Loss vs Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend(fontsize = 'x-large')\n",
        "    plt.show()\n",
        "visualize_training(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ab_CdmTHIM2"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
        "matrix_index = [\"COPD\", \"Healthy\", \"URTI\", \"Bronchiectasis\", \"Pneumoina\", \"Bronchiolitis\"]\n",
        "\n",
        "preds = model.predict(X_test)\n",
        "classpreds = np.argmax(preds, axis=1) # predicted classes \n",
        "y_testclass = np.argmax(y_test, axis=1) # true classes\n",
        "\n",
        "cm = confusion_matrix(y_testclass, classpreds)\n",
        "print(classification_report(y_testclass, classpreds, target_names=matrix_index))\n",
        "\n",
        "# Get percentage value for each element of the matrix\n",
        "cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "cm_perc = cm / cm_sum.astype(float) * 100\n",
        "annot = np.empty_like(cm).astype(str)\n",
        "nrows, ncols = cm.shape\n",
        "for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "        c = cm[i, j]\n",
        "        p = cm_perc[i, j]\n",
        "        if i == j:\n",
        "            s = cm_sum[i]\n",
        "            annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
        "        elif c == 0:\n",
        "            annot[i, j] = ''\n",
        "        else:\n",
        "            annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
        "\n",
        "\n",
        "# Display confusion matrix \n",
        "df_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)\n",
        "df_cm.index.name = 'Actual'\n",
        "df_cm.columns.name = 'Predicted'\n",
        "fig, ax = plt.subplots(figsize=(10,7))\n",
        "sns.heatmap(df_cm, annot=annot, fmt='')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wbgxj9IVYVie"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}