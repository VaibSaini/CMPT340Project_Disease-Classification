# -*- coding: utf-8 -*-
"""Models.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hN6gvnhnJSdLHkk7_v_IkS2srr2IGkR-

# Importing libraries and pre-processed data
"""

# Commented out IPython magic to ensure Python compatibility.

from numpy import argmax
import wave
import random
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np
import os
from os import listdir
from os.path import isfile, join
import pandas as pd 
import pickle as pkl
import seaborn as sns
import scipy
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')
import splitfolders


# ML Libraries
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import mean_squared_error,r2_score, completeness_score, accuracy_score, roc_auc_score, classification_report, confusion_matrix
from sklearn.metrics.cluster import contingency_matrix
from sklearn.model_selection import train_test_split,cross_val_score
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.layers import Conv1D, Conv2D, MaxPooling2D, MaxPooling1D, Dense, Flatten, Dropout, SeparableConv1D
from tensorflow.keras.models import Sequential
from tensorflow.keras.utils import plot_model,to_categorical
import keras
from keras import layers
from keras.layers import Activation, Dense, Dropout, Conv2D, Flatten, MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add
from keras.models import Sequential
from tensorflow.keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator
import splitfolders

from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

dataset = pd.read_pickle('Final_Data.pkl') 

dataset_non_Augmented = dataset[dataset['rand int i'] == -1]
dataset_Augmented = dataset[dataset['rand int i'] != -1]
dataset_Augmented.reset_index(inplace=True)

"""Now we have the joined dataset as well as the split versions to properly organize our models testing and training"""

dataset_sequential_whole = dataset.copy() 
dataset_sequential_Augmented = dataset_Augmented.copy()
dataset_sequential_non_Augmented = dataset_non_Augmented.copy()
dataset

# plt.figure(figsize = (33,33))
# sns.heatmap(dataset.corr().round(1), annot = True)

dataset["Diagnosis"] = dataset["Diagnosis"].astype('category')
dataset["Diagnosis"] = dataset["Diagnosis"].cat.codes
dataset['Binary_diagnosis'] = (dataset['Binary_diagnosis'] == "Healthy").astype(int)

dataset_non_Augmented["Diagnosis"] = dataset_non_Augmented["Diagnosis"].astype('category')
dataset_non_Augmented["Diagnosis"] = dataset_non_Augmented["Diagnosis"].cat.codes
dataset_non_Augmented['Binary_diagnosis'] = (dataset_non_Augmented['Binary_diagnosis'] == "Healthy").astype(int)

dataset_Augmented["Diagnosis"] = dataset_Augmented["Diagnosis"].astype('category')
dataset_Augmented["Diagnosis"] = dataset_Augmented["Diagnosis"].cat.codes
dataset_Augmented['Binary_diagnosis'] = (dataset_Augmented['Binary_diagnosis'] == "Healthy").astype(int)

"""Cat codes work by doing a label encoding alphabetically, so URTI will be 5 because it is lowest """

correlation_heatmap = dataset[['Patient number', 'Sex' ,	'Age'	,'Diagnosis',	'Binary_diagnosis',	'zero_crossing',	'centroids',	'energy',	'new BMI']]
plt.figure(figsize = (33,33))
sns.heatmap(correlation_heatmap.corr().round(1), annot = True)

print("Number of Healthy Patients: ",(dataset['Binary_diagnosis'] == 1).sum())
print("Number of Unhealthy Patients: ",(dataset['Binary_diagnosis'] == 0).sum())
print("\n")
print("Number of Patients with Bronchiectasis are: ",(dataset['Diagnosis'] == 0).sum())
print("Number of Patients with Bronchiolitis are: ",(dataset['Diagnosis'] == 1).sum())
print("Number of Patients with COPD are: ",(dataset['Diagnosis'] == 2).sum())
print("Number of Patients that are Healthy, are: ",(dataset['Diagnosis'] == 3).sum())
print("Number of Patients with Pneumonia are: ",(dataset['Diagnosis'] == 4).sum())
print("Number of Patients with URTI are: ",(dataset['Diagnosis'] == 5).sum())

"""## Multi Classification of Whole Dataset"""

features = dataset.drop(columns = ['Diagnosis','Binary_diagnosis','Patient number','Recording index',"rand int i"])

targets = dataset[['Diagnosis']]

X_train, X_test, y_train, y_test=train_test_split(features, targets, test_size=0.2) # rand state sets a seed so that it will be the same

X_train_whole_dataset = X_train.values
X_test_whole_dataset = X_test.values

y_train_multi_whole_dataset = y_train.values.reshape(-1,)
y_test_multi_whole_dataset = y_test.values.reshape(-1,)

"""## Binary Classification of Whole Dataset"""

# targets = dataset[['Binary_diagnosis']]

# y = targets.values.reshape(-1,)

y_train_binary_whole_dataset = (y_train["Diagnosis"] == 4).astype(int).values.reshape(-1,)
y_test_binary_whole_dataset = (y_test["Diagnosis"] == 4).astype(int).values.reshape(-1,)

"""## Multi Classification of Augmented Dataset"""

features = dataset_Augmented.drop(columns = ['Diagnosis','Binary_diagnosis','Patient number','Recording index',"rand int i"])
targets = dataset_Augmented[['Diagnosis']]

X_train, X_test, y_train, y_test=train_test_split(features, targets, test_size=0.2 , random_state = 5000) # rand state sets a seed so that it will be the same

X_train_augmented_dataset = X_train.values
X_test_augmented_dataset = X_test.values

y_train_multi = y_train.values.reshape(-1,)
y_test_multi = y_test.values.reshape(-1,)

"""## Binary Classification of Augmented Dataset

"""

y_train_binary = (y_train["Diagnosis"] == 4).astype(int).values.reshape(-1,)
y_test_binary = (y_test["Diagnosis"] == 4).astype(int).values.reshape(-1,)

"""Training on the augmented dataset will be interesting, especially in relation to non-augmented

##Non-Augmented Dataset

We want to use the same data rows, so all we do is change the X_trains to be from the non augmented dataset, now the binary and multi classification values will stay the same
"""

X_train_non = dataset_non_Augmented.loc[X_train.index].drop(columns = ['Diagnosis','Binary_diagnosis','Patient number','Recording index',"rand int i"])
X_test_non = dataset_non_Augmented.loc[X_test.index].drop(columns = ['Diagnosis','Binary_diagnosis','Patient number','Recording index',"rand int i"])

X_train_non_augmented_dataset =  X_train_non.values
X_test_non_augmented_dataset = X_test_non.values

"""Training on the augmented dataset will be interesting, especially in relation to non-augmented

# Birch

Firstly, we will work with the augmented and non-augmented datasets that have been split.
"""

from sklearn.decomposition import PCA
from sklearn.cluster import Birch

"""### Binary Diagnosis - Whole Data"""

pca = PCA(2)

X_pca_train = pca.fit_transform(X_train_whole_dataset)
X_pca_test = pca.fit_transform(X_test_whole_dataset)
brc = Birch(n_clusters = 2) 
brc.fit(X_pca_train)

y_train_predict = brc.predict(X_pca_train)
y_test_predict = brc.predict(X_pca_test)

u_labels = np.unique(y_train_predict)
centroids = brc.subcluster_centers_

for i in u_labels:
    plt.scatter(X_pca_train[y_train_predict == i , 0] , X_pca_train[y_train_predict == i , 1] , label = i)

plt.legend()
# # plt.show()

"""As we can notice, it is classifying everything as 1, which for us was healthy. So I will do a calculation to switch up the labels to their proper label.\
Since we know that Unhealthy is vastly bigger
"""

y_train_predict[:] = [abs(x - 1) for x in y_train_predict]
y_test_predict[:] = [abs(x - 1) for x in y_test_predict]

plt.scatter(centroids[:,0] , centroids[:,1] , s = 40, color = 'k')
plt.legend()
# # plt.show()
# Each of these points then is it its own cluster denoted as subcluster in the birch algorithm since, it then gets clustered again based off of distance from each "leaf"

confusion_matrix_train = contingency_matrix(y_train_binary_whole_dataset,y_train_predict)
confusion_matrix_test = contingency_matrix(y_test_binary_whole_dataset,y_test_predict)

confusion = [confusion_matrix_train,confusion_matrix_test]
title = ["confusion_matrix_train","confusion_matrix_test"]
for x in confusion:
  print(x)

for i in range(2):
  fig, ax = plt.subplots(figsize=(10,10))
  sns.heatmap(confusion[i], annot=True)
  plt.xlabel('Predicted')
  plt.ylabel('Actual')
  plt.title(title[i])
  # # plt.show()

print("**Training Score:** {}\\".format(accuracy_score(y_train_binary_whole_dataset,y_train_predict)))
print("**Test Score:** {}\\".format(accuracy_score(y_test_binary_whole_dataset,y_test_predict)))

"""### Multi Diagnosis - Whole Data"""

brc = Birch(n_clusters=6)

brc.fit(X_pca_train)

y_train_predict = brc.predict(X_pca_train)
y_test_predict = brc.predict(X_pca_test)

u_labels = np.unique(y_train_predict)
centroids = brc.subcluster_centers_

for i in u_labels:
    plt.scatter(X_pca_train[y_train_predict == i , 0] , X_pca_train[y_train_predict == i , 1] , label = i)
 

plt.legend()
# plt.show()

confusion_matrix_train = contingency_matrix(y_train_multi_whole_dataset,y_train_predict)
confusion_matrix_test = contingency_matrix(y_test_multi_whole_dataset,y_test_predict)

confusion_matrix_train = confusion_matrix_train[:, [2, 1, 0, 3, 4,5]]
confusion_matrix_test = confusion_matrix_test[:, [2, 1, 0, 3, 4]]

confusion = [confusion_matrix_train,confusion_matrix_test]
title = ["confusion_matrix_train","confusion_matrix_test"]

for i in range(2):
  fig, ax = plt.subplots(figsize=(10,10))
  sns.heatmap(confusion[i], annot=True)
  plt.xlabel('Predicted')
  plt.ylabel('Actual')
  plt.title(title[i])
  # plt.show()

print("**Training Score:** {}\\".format(accuracy_score(y_train_multi_whole_dataset,y_train_predict)))
print("**Test Score:** {}\\".format(accuracy_score(y_test_multi_whole_dataset,y_test_predict)))

"""### Binary Diagnosis - Non Augmented"""

X_pca_train_non_augmented = pca.fit_transform(X_train_non_augmented_dataset)
X_pca_test_non_augmented = pca.fit_transform(X_test_non_augmented_dataset)

brc = Birch(n_clusters=2)

brc.fit(X_pca_train_non_augmented)

y_train_predict = brc.predict(X_pca_train_non_augmented)

y_test_predict = brc.predict(X_pca_test_non_augmented)

u_labels = np.unique(y_train_predict)
centroids = brc.subcluster_centers_

for i in u_labels:
    plt.scatter(X_pca_train_non_augmented[y_train_predict == i , 0] , X_pca_train_non_augmented[y_train_predict == i , 1] , label = i)
 

plt.legend()
# plt.show()

"""Similar thing here where our data is clustered to be 1, but we know from fact that this must be Unhealthy and so I will correct the labels to be consistent with our own ground truth labels"""

y_train_predict[:] = [abs(x - 1) for x in y_train_predict]
y_test_predict[:] = [abs(x - 1) for x in y_test_predict]

confusion_matrix_train = contingency_matrix(y_train_binary,y_train_predict)
confusion_matrix_test = contingency_matrix(y_test_binary,y_test_predict)

confusion = [confusion_matrix_train,confusion_matrix_test]
title = ["confusion_matrix_train_non_augment","confusion_matrix_test_non_augment"]
for x in confusion:
  print(x)

"""We see that our contingency matrix is just a confusion matrix, without the labels so lets make it look nice, however before we do that we also notice that their predicted cluster put everything on 1, but in actuality that clustering label is unhealthy, and is defined as 0 in our dataset"""

for i in range(2):
  fig, ax = plt.subplots(figsize=(10,10))
  sns.heatmap(confusion[i], annot=True)
  plt.xlabel('Predicted')
  plt.ylabel('Actual')
  plt.title(title[i])
  # plt.show()

print("**Training Score:** {}\\".format(accuracy_score(y_train_binary,y_train_predict)))
print("**Test Score:** {}\\".format(accuracy_score(y_test_binary,y_test_predict)))

"""### Multi Diagnosis - Non Augmented"""

brc = Birch(n_clusters=6)

brc.fit(X_pca_train_non_augmented)

y_train_predict = brc.predict(X_pca_train_non_augmented)
y_test_predict = brc.predict(X_pca_test_non_augmented)

u_labels = np.unique(y_train_predict)
centroids = brc.subcluster_centers_

for i in u_labels:
    plt.scatter(X_pca_train_non_augmented[y_train_predict == i , 0] , X_pca_train_non_augmented[y_train_predict == i , 1] , label = i)


plt.legend()
# plt.show()

confusion_matrix_train = contingency_matrix(y_train_multi,y_train_predict)
confusion_matrix_test = contingency_matrix(y_test_multi,y_test_predict)

confusion_matrix_train = confusion_matrix_train[:, [0, 1, 5, 3, 4,2]]
confusion_matrix_test = confusion_matrix_test[:, [0, 1, 4, 3, 2]]
confusion = [confusion_matrix_train,confusion_matrix_test]
title = ["confusion_matrix_train","confusion_matrix_test"]

for i in range(2):
  fig, ax = plt.subplots(figsize=(10,10))
  sns.heatmap(confusion[i], annot=True)
  plt.xlabel('Predicted')
  plt.ylabel('Actual')
  plt.title(title[i])
  # plt.show()

print("**Training Score:** {}\\".format(accuracy_score(y_train_multi,y_train_predict)))
print("**Test Score:** {}\\".format(accuracy_score(y_test_multi,y_test_predict)))

"""### Binary Diagnosis - Augmented"""

X_pca_train_augmented = pca.fit_transform(X_train_augmented_dataset)
X_pca_test_augmented = pca.fit_transform(X_test_augmented_dataset)

brc = Birch(n_clusters=2)

cluster = brc.fit(X_pca_train_augmented)

y_train_predict = brc.predict(X_pca_train_augmented)

y_test_predict = brc.predict(X_pca_test_augmented)

u_labels = np.unique(y_train_predict)
centroids = brc.subcluster_centers_

for i in u_labels:
    plt.scatter(X_pca_train_augmented[y_train_predict == i , 0] , X_pca_train_augmented[y_train_predict == i , 1] , label = i)

plt.legend()
# plt.show()

y_train_predict[:] = [abs(x - 1) for x in y_train_predict]
y_test_predict[:] = [abs(x - 1) for x in y_test_predict]

confusion_matrix_train = contingency_matrix(y_train_binary,y_train_predict)
confusion_matrix_test = contingency_matrix(y_test_binary,y_test_predict)

confusion = [confusion_matrix_train,confusion_matrix_test]
title = ["confusion_matrix_train_non_augment","confusion_matrix_test_non_augment"]
for x in confusion:
  print(x)

for i in range(2):
  fig, ax = plt.subplots(figsize=(10,10))
  sns.heatmap(confusion[i], annot=True)
  plt.xlabel('Predicted')
  plt.ylabel('Actual')
  plt.title(title[i])
  # plt.show()

print("**Training Score:** {}\\".format(accuracy_score(y_train_binary,y_train_predict)))
print("**Test Score:** {}\\".format(accuracy_score(y_test_binary,y_test_predict)))

"""### Multi Diagnosis - Augmented"""

brc = Birch(n_clusters=6)

brc.fit(X_pca_train_augmented)

y_train_predict = brc.predict(X_pca_train_augmented)
y_test_predict = brc.predict(X_pca_test_augmented)

u_labels = np.unique(y_train_predict)
centroids = brc.subcluster_centers_

for i in u_labels:
    plt.scatter(X_pca_train_augmented[y_train_predict == i , 0] , X_pca_train_augmented[y_train_predict == i , 1] , label = i)
 

plt.legend()
# plt.show()

confusion_matrix_train = contingency_matrix(y_train_multi,y_train_predict)
confusion_matrix_test = contingency_matrix(y_test_multi,y_test_predict)

confusion_matrix_train

confusion_matrix_train = confusion_matrix_train[:, [0, 2, 1, 3, 4,5]]
confusion_matrix_test = confusion_matrix_test[:, [0, 2, 1, 3, 4]]

confusion = [confusion_matrix_train,confusion_matrix_test]
title = ["confusion_matrix_train","confusion_matrix_test"]

for i in range(2):
  fig, ax = plt.subplots(figsize=(10,10))
  sns.heatmap(confusion[i], annot=True)
  plt.xlabel('Predicted')
  plt.ylabel('Actual')
  plt.title(title[i])
  # plt.show()

print("**Training Score:** {}\\".format(accuracy_score(y_train_multi,y_train_predict)))
print("**Test Score:** {}\\".format(accuracy_score(y_test_multi,y_test_predict)))

"""#K-Means Model"""

from sklearn.decomposition import PCA
from sklearn.cluster import KMeans

"""### Binary Diagnosis - Whole Data"""

pca = PCA(2)

X_pca_train = pca.fit_transform(X_train_whole_dataset)
X_pca_test = pca.fit_transform(X_test_whole_dataset)
k_means_model = KMeans(n_clusters = 2) 
k_means_model.fit(X_pca_train)

y_train_predict = k_means_model.predict(X_pca_train)
y_test_predict = k_means_model.predict(X_pca_test)

plt.scatter(X_pca_train[:, 0] , X_pca_train[: , 1])
# # plt.savefig('whole_data.png')

u_labels = np.unique(y_train_predict)
centroids = k_means_model.cluster_centers_

for i in u_labels:
    plt.scatter(X_pca_train[y_train_predict == i , 0] , X_pca_train[y_train_predict == i , 1] , label = i)
plt.scatter(centroids[:,0] , centroids[:,1] , s = 40, color = 'k')
# # plt.savefig('KMeans_binary_whole_data.png')
plt.legend()
# plt.show()

"""Clearly we can see from this that 0 must be our unhealthy and 1 must be healthy.  This is easy to re-label """

confusion_matrix_train = contingency_matrix(y_train_binary_whole_dataset,y_train_predict)
confusion_matrix_test = contingency_matrix(y_test_binary_whole_dataset,y_test_predict)

confusion = [confusion_matrix_train,confusion_matrix_test]
title = ["confusion_matrix_train","confusion_matrix_test"]
for x in confusion:
  print(x)

for i in range(2):
  fig, ax = plt.subplots(figsize=(10,10))
  sns.heatmap(confusion[i], annot=True)
  plt.xlabel('Predicted')
  plt.ylabel('Actual')
  plt.title(title[i])
  # plt.show()

print("**Training Score:** {}\\".format(accuracy_score(y_train_binary_whole_dataset,y_train_predict)))
print("**Test Score:** {}\\".format(accuracy_score(y_test_binary_whole_dataset,y_test_predict)))

"""### Multi Diagnosis - Whole Data"""

k_means_model = KMeans(n_clusters=6)

k_means_model.fit(X_pca_train)

y_train_predict = k_means_model.predict(X_pca_train)
y_test_predict = k_means_model.predict(X_pca_test)

u_labels = np.unique(y_train_predict)
centroids = k_means_model.cluster_centers_

for i in u_labels:
    plt.scatter(X_pca_train[y_train_predict == i , 0] , X_pca_train[y_train_predict == i , 1] , label = i)
 
plt.scatter(centroids[:,0] , centroids[:,1] , s = 40, color = 'k')
# # plt.savefig('KMeans_multi_whole_data.png')

plt.legend()
# plt.show()

"""Which cluster is healthy?  Which is unhealthy?  This becomes a challenge"""

confusion_matrix_train = contingency_matrix(y_train_multi_whole_dataset,y_train_predict)
confusion_matrix_test = contingency_matrix(y_test_multi_whole_dataset,y_test_predict)

confusion = [confusion_matrix_train,confusion_matrix_test]
title = ["confusion_matrix_train","confusion_matrix_test"]

for i in range(2):
  fig, ax = plt.subplots(figsize=(10,10))
  sns.heatmap(confusion[i], annot=True)
  plt.xlabel('Predicted')
  plt.ylabel('Actual')
  plt.title(title[i])
  # plt.show()

print("**Training Score:** {}\\".format(accuracy_score(y_train_multi_whole_dataset,y_train_predict)))
print("**Test Score:** {}\\".format(accuracy_score(y_test_multi_whole_dataset,y_test_predict)))

"""### Binary Diagnosis - Non Augmented"""

X_pca_train_non_augmented = pca.fit_transform(X_train_non_augmented_dataset)
X_pca_test_non_augmented = pca.fit_transform(X_test_non_augmented_dataset)

k_means_model = KMeans(n_clusters=2)

k_means_model.fit(X_pca_train_non_augmented)

y_train_predict = k_means_model.predict(X_pca_train_non_augmented)

y_test_predict = k_means_model.predict(X_pca_test_non_augmented)

plt.scatter(X_pca_train_non_augmented[: , 0] , X_pca_train_non_augmented[: , 1])
# # plt.savefig('non_augmented.png')

u_labels = np.unique(y_train_predict)
centroids = k_means_model.cluster_centers_

for i in u_labels:
    plt.scatter(X_pca_train_non_augmented[y_train_predict == i , 0] , X_pca_train_non_augmented[y_train_predict == i , 1] , label = i)
plt.scatter(centroids[:,0] , centroids[:,1] , s = 40, color = 'k')
# # plt.savefig('KMeans_binary_non_augmented_data.png')
plt.legend()
# plt.show()

confusion_matrix_train = contingency_matrix(y_train_binary,y_train_predict)
confusion_matrix_test = contingency_matrix(y_test_binary,y_test_predict)

confusion = [confusion_matrix_train,confusion_matrix_test]
title = ["confusion_matrix_train_non_augment","confusion_matrix_test_non_augment"]
for x in confusion:
  print(x)

"""We see that our contingency matrix is just a confusion matrix, without the labels so lets make it look nice, however before we do that we also notice that their predicted cluster put everything on 1, but in actuality that clustering label is unhealthy, and is defined as 0 in our dataset"""

for i in range(2):
  fig, ax = plt.subplots(figsize=(10,10))
  sns.heatmap(confusion[i], annot=True)
  plt.xlabel('Predicted')
  plt.ylabel('Actual')
  plt.title(title[i])
  # plt.show()

print("**Training Score:** {}\\".format(accuracy_score(y_train_binary,y_train_predict)))
print("**Test Score:** {}\\".format(accuracy_score(y_test_binary,y_test_predict)))

"""### Multi Diagnosis - Non Augmented"""

k_means_model = KMeans(n_clusters=6)

k_means_model.fit(X_pca_train_non_augmented)

y_train_predict = k_means_model.predict(X_pca_train_non_augmented)
y_test_predict = k_means_model.predict(X_pca_test_non_augmented)

u_labels = np.unique(y_train_predict)
centroids = k_means_model.cluster_centers_

for i in u_labels:
    plt.scatter(X_pca_train_non_augmented[y_train_predict == i , 0] , X_pca_train_non_augmented[y_train_predict == i , 1] , label = i)

plt.scatter(centroids[:,0] , centroids[:,1] , s = 40, color = 'k')
# # plt.savefig('KMeans_multi_non_augmented_data.png')


plt.legend()
# plt.show()

confusion_matrix_train = contingency_matrix(y_train_multi,y_train_predict)
confusion_matrix_test = contingency_matrix(y_test_multi,y_test_predict)

confusion = [confusion_matrix_train,confusion_matrix_test]
title = ["confusion_matrix_train","confusion_matrix_test"]

for i in range(2):
  fig, ax = plt.subplots(figsize=(10,10))
  sns.heatmap(confusion[i], annot=True)
  plt.xlabel('Predicted')
  plt.ylabel('Actual')
  plt.title(title[i])
  # plt.show()

print("**Training Score:** {}\\".format(accuracy_score(y_train_multi,y_train_predict)))
print("**Test Score:** {}\\".format(accuracy_score(y_test_multi,y_test_predict)))

"""### Binary Diagnosis - Augmented"""

X_pca_train_augmented = pca.fit_transform(X_train_augmented_dataset)
X_pca_test_augmented = pca.fit_transform(X_test_augmented_dataset)

k_means_model = KMeans(n_clusters=2)

k_means_model.fit(X_pca_train_augmented)

y_train_predict = k_means_model.predict(X_pca_train_augmented)

y_test_predict = k_means_model.predict(X_pca_test_augmented)

confusion_matrix_train = contingency_matrix(y_train_binary,y_train_predict)
confusion_matrix_test = contingency_matrix(y_test_binary,y_test_predict)

confusion = [confusion_matrix_train,confusion_matrix_test]
title = ["confusion_matrix_train_non_augment","confusion_matrix_test_non_augment"]
for x in confusion:
  print(x)

u_labels = np.unique(y_train_predict)
centroids = k_means_model.cluster_centers_

for i in u_labels:
    plt.scatter(X_pca_train_augmented[y_train_predict == i , 0] , X_pca_train_augmented[y_train_predict == i , 1] , label = i)
 
plt.scatter(centroids[:,0] , centroids[:,1] , s = 40, color = 'k')
# # plt.savefig('KMeans_binary_augmented_data.png')


plt.legend()
# plt.show()

for i in range(2):
  fig, ax = plt.subplots(figsize=(10,10))
  sns.heatmap(confusion[i], annot=True)
  plt.xlabel('Predicted')
  plt.ylabel('Actual')
  plt.title(title[i])
  # plt.show()

print("**Training Score:** {}\\".format(accuracy_score(y_train_binary,y_train_predict)))
print("**Test Score:** {}\\".format(accuracy_score(y_test_binary,y_test_predict)))

"""### Multi Diagnosis - Augmented"""

k_means_model = KMeans(n_clusters=6)

k_means_model.fit(X_pca_train_augmented)

y_train_predict = k_means_model.predict(X_pca_train_augmented)
y_test_predict = k_means_model.predict(X_pca_test_augmented)

plt.scatter(X_pca_train_augmented[:,0], X_pca_train_augmented[: , 1])
# # plt.savefig('augmented_data.png')

u_labels = np.unique(y_train_predict)
centroids = k_means_model.cluster_centers_

for i in u_labels:
    plt.scatter(X_pca_train_augmented[y_train_predict == i , 0] , X_pca_train_augmented[y_train_predict == i , 1] , label = i)
 
plt.scatter(centroids[:,0] , centroids[:,1] , s = 40, color = 'k')
# # plt.savefig('KMeans_multi_augmented_data.png')

plt.legend()
# plt.show()

confusion_matrix_train = contingency_matrix(y_train_multi,y_train_predict)
confusion_matrix_test = contingency_matrix(y_test_multi,y_test_predict)

confusion = [confusion_matrix_train,confusion_matrix_test]
title = ["confusion_matrix_train","confusion_matrix_test"]

confusion_matrix_train

confusion_matrix_train = confusion_matrix_train[:,[0,1,5,3,4,2]]
confusion = [confusion_matrix_train,confusion_matrix_test]

confusion_matrix_test

confusion_matrix_test = confusion_matrix_test[:,[0,1,4,3,2]]
confusion = [confusion_matrix_train,confusion_matrix_test]

y_train_predict2 = np.where(y_train_predict == 2, -1, y_train_predict)
y_train_predict2 = np.where(y_train_predict2 == 5, 2, y_train_predict2)
y_train_predict2 = np.where(y_train_predict2 == -1, 5, y_train_predict2)

y_test_predict2 = np.where(y_test_predict == 2, -1, y_test_predict)
y_test_predict2 = np.where(y_test_predict == 4, 2, y_test_predict)
y_test_predict2 = np.where(y_test_predict == -1, 4, y_test_predict)

for i in range(2):
  fig, ax = plt.subplots(figsize=(10,10))
  sns.heatmap(confusion[i], annot=True)
  plt.xlabel('Predicted')
  plt.ylabel('Actual')
  plt.title(title[i])
  # plt.show()

print("**Training Score:** {}\\".format(accuracy_score(y_train_multi,y_train_predict)))
print("**Test Score:** {}\\".format(accuracy_score(y_test_multi,y_test_predict)))

print("**Training Score:** {}\\".format(accuracy_score(y_train_multi,y_train_predict2)))
print("**Test Score:** {}\\".format(accuracy_score(y_test_multi,y_test_predict2)))

"""#Random Forest Model"""

# Creates the model which will later be fitted by training & test sets
random_forest_model = make_pipeline(
    RandomForestClassifier(n_estimators=300),
)

"""##Multi Classification of Whole Dataset using RF

"""

random_forest_model.fit(X_train_whole_dataset, y_train_multi_whole_dataset)

# Print training & validation score
print("Random Forest training score: ", random_forest_model.score(X_train_whole_dataset, y_train_multi_whole_dataset))
print("Random Forest validation score: ", random_forest_model.score(X_test_whole_dataset, y_test_multi_whole_dataset))

"""##Binary Classification of Whole Dataset using RF"""

random_forest_model.fit(X_train_whole_dataset, y_train_binary_whole_dataset)

# Print training & validation score
print("Random Forest training score: ", random_forest_model.score(X_train_whole_dataset, y_train_binary_whole_dataset))
print("Random Forest validation score: ", random_forest_model.score(X_test_whole_dataset, y_test_binary_whole_dataset))

"""## Multi Classification of Augmented Dataset using RF"""

random_forest_model.fit(X_train_augmented_dataset, y_train_multi)

# Print training & validation score
print("Random Forest training score: ", random_forest_model.score(X_train_augmented_dataset, y_train_multi))
print("Random Forest validation score: ", random_forest_model.score(X_test_augmented_dataset, y_test_multi))

"""## Binary Classification of Augmented Dataset using RF

"""

random_forest_model.fit(X_train_augmented_dataset, y_train_binary)

# Print training & validation score
print("Random Forest training score: ", random_forest_model.score(X_train_augmented_dataset, y_train_binary))
print("Random Forest validation score: ", random_forest_model.score(X_test_augmented_dataset, y_test_binary))

"""## Multi Classification of Non-Augmented Dataset using RF"""

random_forest_model.fit(X_train_non_augmented_dataset, y_train_multi)

# Print training & validation score
print("Random Forest training score: ", random_forest_model.score(X_train_non_augmented_dataset, y_train_multi))
print("Random Forest validation score: ", random_forest_model.score(X_test_non_augmented_dataset, y_test_multi))

"""## Binary Classification of Non-Augmented Dataset using RF



"""

random_forest_model.fit(X_train_non_augmented_dataset, y_train_binary)

# Print training & validation score
print("Random Forest training score: ", random_forest_model.score(X_train_non_augmented_dataset, y_train_binary))
print("Random Forest validation score: ", random_forest_model.score(X_test_non_augmented_dataset, y_test_binary))

"""# Sequential Modelling

### Sequential Model using Features

##### Processing and Modelling

refining and spliting data
"""

def data_points(data, patient_diagnosis):
    labels = []
    images = []

    to_hot_one = {"COPD":0, "Healthy":1, "URTI":2, "Bronchiectasis":3, "Pneumonia":4, "Bronchiolitis":5, "Asthma":6, "LRTI":7}

    #count = 0
    for i in range (0, patient_diagnosis.size):
      labels.append(to_hot_one[patient_diagnosis[i]])
      images.append(np.array(data.iloc[i, :]))

    return np.array(labels), np.array(images)

def preprocessing(labels, images):    

  # Split data
    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=10)

  # one hot encoding
    y_train = to_categorical(y_train)
    y_test = to_categorical(y_test)  

  # Format new data
    y_train = np.reshape(y_train, (y_train.shape[0], 6))
    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
    y_test = np.reshape(y_test, (y_test.shape[0], 6))
    X_test = np.reshape(X_test, (X_test.shape[0], X_train.shape[1],  1))

    return X_train, X_test, y_train, y_test

"""sequential model implimentation and training"""

model = Sequential()
model.add(Conv1D(64, kernel_size=5, activation='relu', input_shape=(193, 1)))

model.add(Conv1D(128, kernel_size=5, activation='relu'))
model.add(MaxPooling1D(2)) 

model.add(SeparableConv1D(256, kernel_size=5, activation='relu'))
model.add(MaxPooling1D(2)) 

model.add(SeparableConv1D(256, kernel_size=5, activation='relu'))
model.add(MaxPooling1D(2)) 

model.add(Dropout(0.5))
model.add(Flatten())

model.add(Dense(512, activation='relu'))   
model.add(Dense(6, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""##### Augumented Dataset"""

#extracting the required data
dataset_sequential = dataset_sequential_Augmented.copy()
dataset_sequential.columns = dataset_sequential.columns.map(str)
start = dataset_sequential.columns.get_loc("0") 
end = dataset_sequential.columns.get_loc("192")
data = dataset_sequential.iloc[:, start: end]
patient_diagnosis = dataset_sequential.iloc[:, dataset_sequential.columns.get_loc("Diagnosis")]

labels, images = data_points(data, patient_diagnosis)

X_train, X_test, y_train, y_test = preprocessing(labels, images)

history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=70, batch_size=200, verbose=1)

"""visualizing the results"""

def visualize_training(history, lw = 3):
    plt.figure(figsize=(10,6))
    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)
    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)
    plt.title('Training Accuracy vs Validation Accuracy for Augumented Data')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend(fontsize = 'x-large')
    # plt.show()

    plt.figure(figsize=(10,6))
    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)
    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)
    plt.title('Training Loss vs Validation Loss for Augumented Data')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend(fontsize = 'x-large')
    # plt.show()
visualize_training(history)

# confusion mattrix and classification report
matrix_index = ["COPD", "Healthy", "URTI", "Bronchiectasis", "Pneumoina", "Bronchiolitis"]

preds = model.predict(X_test)
classpreds = np.argmax(preds, axis=1) # predicted classes 
y_testclass = np.argmax(y_test, axis=1) # true classes

cm = confusion_matrix(y_testclass, classpreds)
print(classification_report(y_testclass, classpreds, target_names=matrix_index))

# Get percentage value for each element of the matrix
cm_sum = np.sum(cm, axis=1, keepdims=True)
cm_perc = cm / cm_sum.astype(float) * 100
annot = np.empty_like(cm).astype(str)
nrows, ncols = cm.shape
for i in range(nrows):
    for j in range(ncols):
        c = cm[i, j]
        p = cm_perc[i, j]
        if i == j:
            s = cm_sum[i]
            annot[i, j] = '%.1f%%\n%d/%d' % (p, c, s)
        elif c == 0:
            annot[i, j] = ''
        else:
            annot[i, j] = '%.1f%%\n%d' % (p, c)


# Display confusion matrix 
df_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)
df_cm.index.name = 'Actual'
df_cm.columns.name = 'Predicted'
fig, ax = plt.subplots(figsize=(10,7))
sns.heatmap(df_cm, annot=annot, fmt='')

"""evaluating model's efficiency"""

augumented_evaluation = model.evaluate(X_test, y_test)

"""##### Non Augumented Dataset"""

dataset_sequential = dataset_sequential_non_Augmented.copy()
dataset_sequential.columns = dataset_sequential.columns.map(str)

start = dataset_sequential.columns.get_loc("0") 
end = dataset_sequential.columns.get_loc("192")

data = dataset_sequential.iloc[:, start: end]

patient_diagnosis = dataset_sequential.iloc[:, dataset_sequential.columns.get_loc("Diagnosis")]

labels, images = data_points(data, patient_diagnosis)

X_train, X_test, y_train, y_test = preprocessing(labels, images)

history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=70, batch_size=200, verbose=1)

"""visualizing the results"""

def visualize_training(history, lw = 3):
    plt.figure(figsize=(10,6))
    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)
    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)
    plt.title('Training Accuracy vs Validation Accuracy for Non-Augumented Dataset')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend(fontsize = 'x-large')
    # plt.show()

    plt.figure(figsize=(10,6))
    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)
    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)
    plt.title('Training Loss vs Validation Loss for Non-Augumented Dataset')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend(fontsize = 'x-large')
    # plt.show()
visualize_training(history)

from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix
matrix_index = ["COPD", "Healthy", "URTI", "Bronchiectasis", "Pneumoina", "Bronchiolitis"]

preds = model.predict(X_test)
classpreds = np.argmax(preds, axis=1) # predicted classes 
y_testclass = np.argmax(y_test, axis=1) # true classes

cm = confusion_matrix(y_testclass, classpreds)
print(classification_report(y_testclass, classpreds, target_names=matrix_index))

# Get percentage value for each element of the matrix
cm_sum = np.sum(cm, axis=1, keepdims=True)
cm_perc = cm / cm_sum.astype(float) * 100
annot = np.empty_like(cm).astype(str)
nrows, ncols = cm.shape
for i in range(nrows):
    for j in range(ncols):
        c = cm[i, j]
        p = cm_perc[i, j]
        if i == j:
            s = cm_sum[i]
            annot[i, j] = '%.1f%%\n%d/%d' % (p, c, s)
        elif c == 0:
            annot[i, j] = ''
        else:
            annot[i, j] = '%.1f%%\n%d' % (p, c)


# Display confusion matrix 
df_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)
df_cm.index.name = 'Actual'
df_cm.columns.name = 'Predicted'
fig, ax = plt.subplots(figsize=(10,7))
sns.heatmap(df_cm, annot=annot, fmt='')

"""evaluating model's efficiency"""

non_augumented_evaluation = model.evaluate(X_test, y_test)

"""##### Whole Dataset"""

dataset_sequential = dataset_sequential_whole.copy()
dataset_sequential.columns = dataset_sequential.columns.map(str)

start = dataset_sequential.columns.get_loc("0") 
end = dataset_sequential.columns.get_loc("192")

data = dataset_sequential.iloc[:, start: end]

patient_diagnosis = dataset_sequential.iloc[:, dataset_sequential.columns.get_loc("Diagnosis")]

labels, images = data_points(data, patient_diagnosis)

X_train, X_test, y_train, y_test = preprocessing(labels, images)

history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=70, batch_size=200, verbose=1)

"""visualizing the results"""

def visualize_training(history, lw = 3):
    plt.figure(figsize=(10,6))
    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)
    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)
    plt.title('Training Accuracy vs Validation Accuracy for Whole Dataset')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend(fontsize = 'x-large')
    # plt.show()

    plt.figure(figsize=(10,6))
    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)
    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)
    plt.title('Training Loss vs Validation Loss for Whole Dataset')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend(fontsize = 'x-large')
    # plt.show()
visualize_training(history)

from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix
matrix_index = ["COPD", "Healthy", "URTI", "Bronchiectasis", "Pneumoina", "Bronchiolitis"]

preds = model.predict(X_test)
classpreds = np.argmax(preds, axis=1) # predicted classes 
y_testclass = np.argmax(y_test, axis=1) # true classes

cm = confusion_matrix(y_testclass, classpreds)
print(classification_report(y_testclass, classpreds, target_names=matrix_index))

# Get percentage value for each element of the matrix
cm_sum = np.sum(cm, axis=1, keepdims=True)
cm_perc = cm / cm_sum.astype(float) * 100
annot = np.empty_like(cm).astype(str)
nrows, ncols = cm.shape
for i in range(nrows):
    for j in range(ncols):
        c = cm[i, j]
        p = cm_perc[i, j]
        if i == j:
            s = cm_sum[i]
            annot[i, j] = '%.1f%%\n%d/%d' % (p, c, s)
        elif c == 0:
            annot[i, j] = ''
        else:
            annot[i, j] = '%.1f%%\n%d' % (p, c)


# Display confusion matrix 
df_cm = pd.DataFrame(cm, index = matrix_index, columns = matrix_index)
df_cm.index.name = 'Actual'
df_cm.columns.name = 'Predicted'
fig, ax = plt.subplots(figsize=(10,7))
sns.heatmap(df_cm, annot=annot, fmt='')

"""evaluating model's efficiency"""

whole_evaluation = model.evaluate(X_test, y_test)

"""##### Summary"""

augumented_evaluation

non_augumented_evaluation

whole_evaluation

"""### Sequential model with spectograms"""

datagen = ImageDataGenerator(
        rescale=1./255, 
        shear_range=0.2, 
        zoom_range=0.2, 
        horizontal_flip=True)

training_set = datagen.flow_from_directory(
        'Data/train',
        target_size=(64, 64),
        batch_size=1,
        class_mode='categorical',
        shuffle = False)

test_set = datagen.flow_from_directory(
        'Data/test',
        target_size=(64, 64),
        batch_size=1,
        class_mode='categorical',
        shuffle = False )

val_set = datagen.flow_from_directory(
        'Data/val',
        target_size=(64, 64),
        batch_size=1,
        class_mode='categorical',
        shuffle = False )

model = Sequential()
input_shape=(64, 64, 3)#1st hidden layer
model.add(Conv2D(32, (3, 3), strides=(2, 2), input_shape=input_shape))
model.add(AveragePooling2D((2, 2), strides=(2,2)))
model.add(Activation('relu'))#2nd hidden layer
model.add(Conv2D(64, (3, 3), padding="same"))
model.add(AveragePooling2D((2, 2), strides=(2,2)))
model.add(Activation('relu'))#3rd hidden layer
model.add(Conv2D(64, (3, 3), padding="same"))
model.add(AveragePooling2D((2, 2), strides=(2,2)))
model.add(Activation('relu'))#Flatten
model.add(Flatten())
model.add(Dropout(rate=0.5))#Add fully connected layer.
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(rate=0.5))#Output layer
model.add(Dense(6))
model.add(Activation('softmax'))
model.summary()

epochs = 255
batch_size = 8
learning_rate = 0.01
decay_rate = learning_rate / epochs
momentum = 0.9
sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)
model.compile(optimizer="sgd", loss="categorical_crossentropy", metrics=['accuracy'])

history = model.fit(
        training_set,
        steps_per_epoch=50,
        epochs=50,
        validation_data=val_set,
        validation_steps=165)

print('the accuracy score of the model is: ' + str(model.evaluate_generator(generator=test_set, steps=50)[1]))

"""# KNN Model """

#setting up KNN model with the help of Grid search CV for hyperparameters tuning

k_range = list(range(3,21)) #compare classification results between 3-20 neighbours
param_grid = {
    'n_neighbors': k_range,
    'weights': ['uniform', 'distance'],
    'metric': ['euclidean', 'manhattan']
}

# Scaler to tranform the data before fitting to the model
scaler = StandardScaler()

"""## Whole dataset"""

#Fitting whole dataset
scaler.fit(X_train_whole_dataset)
x_train_scaled_whole = scaler.transform(X_train_whole_dataset)
x_test_scaled_whole = scaler.transform(X_test_whole_dataset)

#using PCA to reduce dimensionality
pca = PCA().fit(x_train_scaled_whole)
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('Number of Components')
plt.ylabel('Variance (%)')
plt.title('Variance vs No of Components for Whole Dataset')
# plt.savefig('vc-whole.png')
# plt.show()

"""### Multi classification"""

model = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, n_jobs=-1, scoring='accuracy')
model.fit(x_train_scaled_whole, y_train_multi_whole_dataset)
print(" ")
print("---- Multi-disease classification on the whole dataset ----")
print(f'Model Training Score: {model.score(x_train_scaled_whole, y_train_multi_whole_dataset)}')
print(f'Model Testing Score: {model.score(x_test_scaled_whole, y_test_multi_whole_dataset)}')
print(" ")

y_predict_whole_multi = model.predict(x_test_scaled_whole)
print(f'Confusion Matrix: \n{confusion_matrix(y_test_multi_whole_dataset,y_predict_whole_multi)}')
print(" ")

# create confusion matrix heatmap for predictions
contingency = contingency_matrix(y_test_multi_whole_dataset,y_predict_whole_multi)
plt.subplots(figsize=(10,10))
sns.heatmap(contingency, annot=True)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Multi-disease classification on whole dataset (ACC = ' + str(round(model.score(x_test_scaled_whole, y_test_multi_whole_dataset),5)) + ')')
# plt.savefig('heatmap-whole-multi.png')
# plt.show()

"""### Binary classification"""


model = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, n_jobs=-1, scoring='accuracy')
model.fit(x_train_scaled_whole, y_train_binary_whole_dataset)
print(" ")
print("---- Binary-disease classification on the whole dataset ----")
print(f'Model Training Score: {model.score(x_train_scaled_whole, y_train_binary_whole_dataset)}')
print(f'Model Testing Score: {model.score(x_test_scaled_whole, y_test_binary_whole_dataset)}')
print(" ")
y_predict_whole_bin = model.predict(x_test_scaled_whole)
print(f'Confusion Matrix: \n{confusion_matrix(y_test_binary_whole_dataset,y_predict_whole_bin)}')
print(" ")

# create confusion matrix heatmap for predictions
contingency = contingency_matrix(y_test_binary_whole_dataset,y_predict_whole_bin)
fig, ax = plt.subplots(figsize=(10,10))
sns.heatmap(contingency, annot=True)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Binary classification on whole dataset (ACC = ' + str(round(model.score(x_test_scaled_whole, y_test_binary_whole_dataset),5)) + ')')
# plt.savefig('heatmap-whole-bin.png')
# plt.show()

"""## Augmented dataset"""

#Fitting Augmented data
scaler.fit(X_train_augmented_dataset)
x_train_scaled_aug = scaler.transform(X_train_augmented_dataset)
x_test_scaled_aug = scaler.transform(X_test_augmented_dataset)

pca = PCA().fit(x_train_scaled_aug)
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('Number of Components')
plt.ylabel('Variance (%)')
plt.title('Variance vs No of Components for Augmented Dataset')
# plt.savefig('vc-aug.png')
# plt.show()

"""### Multi classification"""

model = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, n_jobs=-1, scoring='accuracy')
model.fit(x_train_scaled_aug, y_train_multi)

print(" ")
print("---- Multi-disease classification on the augmented dataset ----")
print(f'Model Training Score: {model.score(x_train_scaled_aug, y_train_multi)}')
print(f'Model Testing Score: {model.score(x_test_scaled_aug, y_test_multi)}')
print(" ")
y_predict_aug_multi = model.predict(x_test_scaled_aug)
print(f'Confusion Matrix: \n{confusion_matrix(y_test_multi,y_predict_aug_multi)}')
print(" ")

# create confusion matrix heatmap for predictions
contingency = contingency_matrix(y_test_multi,y_predict_aug_multi)
fig, ax = plt.subplots(figsize=(10,10))
sns.heatmap(contingency, annot=True)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Multi-classification on augmented dataset (ACC = ' + str(round(model.score(x_test_scaled_aug, y_test_multi),5)) + ')')
# plt.savefig('heatmap-aug-multi.png')
# plt.show()

"""### Binary classification"""

model = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, n_jobs=-1, scoring='accuracy')
model.fit(x_train_scaled_aug, y_train_binary)

print(" ")
print("---- Binary-disease classification on the augmented dataset ----")
print(f'Model Training Score: {model.score(x_train_scaled_aug, y_train_binary)}')
print(f'Model Testing Score: {model.score(x_test_scaled_aug, y_test_binary)}')
print(" ")
y_predict_aug_bin = model.predict(x_test_scaled_aug)
print(f'Confusion Matrix: \n{confusion_matrix(y_test_binary,y_predict_aug_bin)}')
print(" ")

# create confusion matrix heatmap for predictions
contingency = contingency_matrix(y_test_binary,y_predict_aug_bin)
fig, ax = plt.subplots(figsize=(10,10))
sns.heatmap(contingency, annot=True)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Binary classification on augmented dataset (ACC = ' + str(round(model.score(x_test_scaled_aug, y_test_binary),5)) + ')')
# plt.savefig('heatmap-aug-bin.png')
# plt.show()

"""## Non-Augmented dataset"""

scaler.fit(X_train_non_augmented_dataset)
x_train_scaled_na = scaler.transform(X_train_non_augmented_dataset)
x_test_scaled_na = scaler.transform(X_test_non_augmented_dataset)

pca = PCA().fit(x_train_scaled_na)
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('Number of Components')
plt.ylabel('Variance (%)')
plt.title('Variance vs No of Components for Non-Augmented Dataset')
# plt.savefig('vc-na.png')
# plt.show()

"""### Multi classification"""

model = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, n_jobs=-1, scoring='accuracy')
model.fit(x_train_scaled_na, y_train_multi)

print(" ")
print("---- Multi-disease classification on the non-augmented dataset ----")
print(f'Model Training Score: {model.score(x_train_scaled_na, y_train_multi)}')
print(f'Model Testing Score: {model.score(x_test_scaled_na, y_test_multi)}')
print(" ")
y_predict_na_multi = model.predict(x_test_scaled_na)
print(f'Confusion Matrix: \n{confusion_matrix(y_test_multi,y_predict_na_multi)}')
print(" ")

# create confusion matrix heatmap for predictions
contingency = contingency_matrix(y_test_multi,y_predict_na_multi)
fig, ax = plt.subplots(figsize=(10,10))
sns.heatmap(contingency, annot=True)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Multi-classification on non-augmented dataset (ACC = ' + str(round(model.score(x_test_scaled_na, y_test_multi),5)) + ')')
# plt.savefig('heatmap-na-multi.png')
# plt.show()
"""### Binary classification """

model = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5, n_jobs=-1, scoring='accuracy')
model.fit(x_train_scaled_na, y_train_binary)

print(" ")
print("---- Multi-disease classification on the non-augmented dataset ----")
print(f'Model Training Score: {model.score(x_train_scaled_na, y_train_binary)}')
print(f'Model Testing Score: {model.score(x_test_scaled_na, y_test_binary)}')
print(" ")
y_predict_na_bin = model.predict(x_test_scaled_na)
print(f'Confusion Matrix: \n{confusion_matrix(y_test_binary,y_predict_na_bin)}')
print(" ")

# create confusion matrix heatmap for predictions
contingency = contingency_matrix(y_test_binary,y_predict_na_bin)
fig, ax = plt.subplots(figsize=(10,10))
sns.heatmap(contingency, annot=True)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Binary classification on non-augmented dataset (ACC = ' + str(round(model.score(x_test_scaled_na, y_test_binary),5)) + ')')
# plt.savefig('heatmap-na-bin.png')
# plt.show()